{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARTchives: a data driven historiography of art history - Jupyter Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter Notebook is integral part of the research carried out by Lucia Giagnolini for her master's thesis in Knowledge organization and Cultural Heritage, Digital Humanities and Digital Knowledge international degree a. y. 2020/2021."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The focus of the thesis is the recently published ARTchives project, which can be accessed at: http://artchives.fondazionezeri.unibo.it. ARTchives is the first international web-based platform for a census of art historians' archives. It is an integrated system that collects archival descriptions of notable art historians' collections and opens up unexplored research paths through the implementation of semantic web technologies. Being a nascent project, there is considerable margin for improvement in several aspects. At the moment, one of the most compelling needs is to better exploit the potential of ARTchives and, in particular, of Semantic Web technologies underlying the system. A way to achieve this goal is to enhance communication and visual aspects by introducing new data visualizations to the ones aready published in the dedicated section.\n",
    "The work presented in this Notebook aims at providing further data visualization proposals, not yet published in the application but in the view of an actual implementation in the next releases of ARTchives. The starting point for the development of these visualizations were four fundamental research questions:\n",
    "1. RQ1. What have been the places of education and activity of all the art historians recorded in ARTchives?\n",
    "2. RQ2. What have been the places of education and activity of a particular art historian recorded in ARTchives?\n",
    "3. RQ3. What were the relations of art historians with other experts of their times (other scholars, art collectors, connoisseurs etc.)?\n",
    "4. RQ4. Which artists and personalities have been studied by art historians recorded in ARTchives?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The distribution of art historians’ places of education and activity: visualizing RQ1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<http://www.wikidata.org/entity/Q18935222>', '<http://www.wikidata.org/entity/Q2824734>', '<http://www.wikidata.org/entity/Q995470>', '<http://www.wikidata.org/entity/Q19997512>', '<http://www.wikidata.org/entity/Q60185>', '<http://www.wikidata.org/entity/Q1089074>', '<http://www.wikidata.org/entity/Q1712683>', '<http://www.wikidata.org/entity/Q90407>', '<http://www.wikidata.org/entity/Q6700132>', '<http://www.wikidata.org/entity/Q88907>', '<http://www.wikidata.org/entity/Q85761254>', '<http://www.wikidata.org/entity/Q61913691>', '<http://www.wikidata.org/entity/Q1373290>', '<http://www.wikidata.org/entity/Q1629748>', '<http://www.wikidata.org/entity/Q537874>', '<http://www.wikidata.org/entity/Q457739>', '<http://www.wikidata.org/entity/Q55453618>', '<http://www.wikidata.org/entity/Q1296486>', '<http://www.wikidata.org/entity/Q1715096>', '<http://www.wikidata.org/entity/Q1641821>', '<http://www.wikidata.org/entity/Q3051533>', '<http://www.wikidata.org/entity/Q3057287>', '<http://www.wikidata.org/entity/Q41616785>', '<http://www.wikidata.org/entity/Q1271052>'}\n",
      "['Federico Zeri', '<http://www.wikidata.org/entity/Q1089074>', 'Leo Steinberg', '<http://www.wikidata.org/entity/Q457739>', 'Kurt Badt', '<http://www.wikidata.org/entity/Q1629748>', 'Richard Krautheimer', '<http://www.wikidata.org/entity/Q90407>', 'Luisa Vertova', '<http://www.wikidata.org/entity/Q61913691>', 'Julian Kliemann', '<http://www.wikidata.org/entity/Q85761254>', 'John Pope-Hennessy', '<http://www.wikidata.org/entity/Q537874>', 'Ulrich Middeldorf', '<http://www.wikidata.org/entity/Q1715096>', 'Ellis Waterhouse', '<http://www.wikidata.org/entity/Q3051533>', 'Ernst Kitzinger', '<http://www.wikidata.org/entity/Q88907>', 'Julius S. Held', '<http://www.wikidata.org/entity/Q1712683>', 'Wolfgang Lotz', '<http://www.wikidata.org/entity/Q1296486>', 'Adolfo Venturi', '<http://www.wikidata.org/entity/Q2824734>', 'Eugenio Battisti', '<http://www.wikidata.org/entity/Q1373290>', 'Stefano Tumidei', '<http://www.wikidata.org/entity/Q55453618>', 'Aby Warburg', '<http://www.wikidata.org/entity/Q60185>', 'Kornél Fabriczy', '<http://www.wikidata.org/entity/Q995470>', 'Werner Cohn', '<http://www.wikidata.org/entity/Q18935222>', 'Gustav Ludwig', '<http://www.wikidata.org/entity/Q41616785>', 'Fritz Heinemann', '<http://www.wikidata.org/entity/Q1271052>', 'Luigi Salerno', '<http://www.wikidata.org/entity/Q6700132>', 'Everett Fahy', '<http://www.wikidata.org/entity/Q19997512>', 'Ernst Steinmann', '<http://www.wikidata.org/entity/Q3057287>', 'Otto Lehmann-Brockhaus', '<http://www.wikidata.org/entity/Q1641821>']\n"
     ]
    }
   ],
   "source": [
    "#! pip install rdflib\n",
    "import rdflib\n",
    "from rdflib import Namespace , Literal , URIRef\n",
    "from rdflib.namespace import RDF , RDFS\n",
    "\n",
    "# create an empty Graph\n",
    "g = rdflib.ConjunctiveGraph()\n",
    "\n",
    "# parse a local RDF file by specifying the format\n",
    "result = g.parse(\"artchives.nq\", format='nquads') #Desktop/dhdk_epds/resources/\n",
    "\n",
    "# bind the uncommon namespaces\n",
    "wd = Namespace(\"http://www.wikidata.org/entity/\") # remember that a prefix matches a URI until the last slash (or hashtag #)\n",
    "wdt = Namespace(\"http://www.wikidata.org/prop/direct/\")\n",
    "art = Namespace(\"https://w3id.org/artchives/\")\n",
    "rdfs = Namespace (\"http://www.w3.org/2000/01/\")\n",
    "\n",
    "# Get the list of art historians in our graph \"g\"\n",
    "arthistorians_list = set()\n",
    "arthistorians_names = list()\n",
    "\n",
    "# iterate over the triples in the graph\n",
    "for s,p,o in g.triples(( None, wdt.P170, None)):\n",
    "    for subj, prop, obj in g.triples((o, RDFS.label, None )):# people \"o\" are the creator \"wdt.P170\" of a collection \"s\"\n",
    "        if \"wikidata.org/entity/\" in str(o):           # look for the substring to filter wikidata entities only\n",
    "            arthistorians_list.add('<' + str(o) + '>')\n",
    "            if obj.strip() not in arthistorians_names:\n",
    "                arthistorians_names.append(obj.strip())\n",
    "                arthistorians_names.append('<' + str(o) + '>')  # remember to transform them in strings! \n",
    "    \n",
    "#print(arthistorians_list)\n",
    "#print(arthistorians_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install SPARQLWrapper\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "# get the endpoint API\n",
    "wikidata_endpoint = \"https://query.wikidata.org/bigdata/namespace/wdq/sparql\"\n",
    "\n",
    "# prepare the values to be queried\n",
    "historians = ' '.join(arthistorians_list) # <uri1> <uri2> <uri3> ... <uriN>\n",
    "#print(historians)\n",
    "# prepare the query: for each historian in ARTchives check in wikidata if there are work or education places.\n",
    "formationplace_query = \"\"\" \n",
    "PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
    "SELECT DISTINCT ?historian ?workplace ?workplace_label ?coordinates1 ?eduplace ?eduplace_label ?coordinates2 (group_concat(?type ; separator=\"; \") as ?place_type) (group_concat(?type_label ; separator=\"; \") as ?label)\n",
    "WHERE {\n",
    "    VALUES ?historian {\"\"\"+historians+\"\"\"} . \n",
    "    optional {?historian wdt:P108 ?workplace . \n",
    "    ?workplace rdfs:label ?workplace_label .\n",
    "    FILTER (langMatches(lang(?workplace_label), \"EN\")) \n",
    "    ?workplace wdt:P625 ?coordinates1; wdt:P31 ?type . \n",
    "    ?type rdfs:label ?type_label . \n",
    "    FILTER (langMatches(lang(?type_label), \"EN\"))}\n",
    "    optional {?historian wdt:P69 ?eduplace . \n",
    "    ?eduplace rdfs:label ?eduplace_label .\n",
    "    FILTER (langMatches(lang(?eduplace_label), \"EN\")) \n",
    "    ?eduplace wdt:P625 ?coordinates2; wdt:P31 ?type . \n",
    "    ?type rdfs:label ?type_label . \n",
    "    FILTER (langMatches(lang(?type_label), \"EN\")) }\n",
    "    } \n",
    "GROUP BY ?historian ?workplace ?workplace_label ?coordinates1 ?eduplace ?eduplace_label ?coordinates2 ?place_type ?label\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "# set the endpoint \n",
    "sparql_wd = SPARQLWrapper(wikidata_endpoint)\n",
    "# set the query\n",
    "sparql_wd.setQuery(formationplace_query)\n",
    "# set the returned format\n",
    "sparql_wd.setReturnFormat(JSON)\n",
    "# get the results\n",
    "results = sparql_wd.query().convert()\n",
    "\n",
    "# manipulate the result\n",
    "for result in results[\"results\"][\"bindings\"]:\n",
    "    #print(result)\n",
    "    historian_uri = result[\"historian\"][\"value\"]\n",
    "    #print(\"historian:\", historian_uri)\n",
    "    if \"workplace\" in result: \n",
    "        workplace = result[\"workplace\"][\"value\"]\n",
    "        if \"workplace_label\" in result and \"coordinates1\" in result: \n",
    "            workplace_label = result[\"workplace_label\"][\"value\"]\n",
    "            work_coord = result[\"coordinates1\"][\"value\"][6:-1].split(\" \")\n",
    "            #print(work_coord)\n",
    "            #print(\"work:\", workplace, workplace_label)\n",
    "\n",
    "                    # only if uri, label and coords are found we add them to the graph\n",
    "            g.add(( URIRef(historian_uri) , URIRef(wdt.P108) , URIRef(workplace) ))\n",
    "            g.add(( URIRef(workplace) , RDFS.label , Literal(workplace_label) ))\n",
    "            g.add(( URIRef(workplace) , URIRef(wdt.P625) , Literal(work_coord) ))\n",
    "            if \"place_type\" in result: \n",
    "                type_label = result[\"label\"][\"value\"].split(\" \")[0]\n",
    "                #print(type_label)\n",
    "                place_type = result[\"place_type\"][\"value\"].split(\";\")[0]\n",
    "                #print(\"WORK \", workplace_label, type_label, place_type)\n",
    "                if type_label != \"\":\n",
    "                    g.add(( URIRef(workplace) , URIRef(wdt.P31) , URIRef(place_type) ))\n",
    "                    g.add(( URIRef(place_type) , RDFS.label  , Literal(type_label) ))\n",
    "                    \n",
    "            \n",
    "    if \"eduplace\" in result: \n",
    "        eduplace = result[\"eduplace\"][\"value\"]\n",
    "        #print(eduplace)\n",
    "        if \"eduplace_label\" in result and \"coordinates2\" in result: \n",
    "            eduplace_label = result[\"eduplace_label\"][\"value\"]\n",
    "            eduplace_coord = result[\"coordinates2\"][\"value\"][6:-1].split(\" \")\n",
    "            #print(\"education:\", eduplace, eduplace_label)\n",
    "                    # only if both uri and label are found we add them to the graph\n",
    "            g.add(( URIRef(historian_uri) , URIRef(wdt.P69) , URIRef(eduplace) ))\n",
    "            g.add(( URIRef(eduplace) , RDFS.label , Literal(eduplace_label) ))\n",
    "            g.add(( URIRef(eduplace) , URIRef(wdt.P625) , Literal(eduplace_coord) ))\n",
    "            if \"place_type\" in result: \n",
    "                type_label = result[\"label\"][\"value\"].split(\" \")[0]\n",
    "                place_type = result[\"place_type\"][\"value\"].split(\";\")[0]\n",
    "                #print(\"EDUCATION \", eduplace_label, type_label, place_type)\n",
    "                if type_label != \"\":\n",
    "                    g.add(( URIRef(eduplace) , URIRef(wdt.P31) , URIRef(place_type) ))\n",
    "                    g.add(( URIRef(place_type) , RDFS.label  , Literal(type_label) ))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.serialize(destination='artchives2.nq', format='nquads') #Desktop/dhdk_epds/resources/\n",
    "result = g.parse(\"artchives2.nq\", format='nquads')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Vassar College', '<http://www.wikidata.org/entity/Q2093794>', 41.686, -73.89, 'institution') [('<http://www.wikidata.org/entity/Q90407>', 'Richard Krautheimer'), ('<http://www.wikidata.org/entity/Q1296486>', 'Wolfgang Lotz')]\n",
      "('University of Virginia', '<http://www.wikidata.org/entity/Q213439>', 38.035, -78.5, 'institution') [('<http://www.wikidata.org/entity/Q19997512>', 'Everett Fahy')]\n",
      "('University of Marburg', '<http://www.wikidata.org/entity/Q155354>', 50.81, 8.7736, 'institution') [('<http://www.wikidata.org/entity/Q90407>', 'Richard Krautheimer')]\n",
      "('Sapienza University of Rome', '<http://www.wikidata.org/entity/Q209344>', 41.903, 12.515, 'institution') [('<http://www.wikidata.org/entity/Q1089074>', 'Federico Zeri'), ('<http://www.wikidata.org/entity/Q2824734>', 'Adolfo Venturi')]\n",
      "('Harvard University', '<http://www.wikidata.org/entity/Q13371>', 42.374, -71.11, 'institution') [('<http://www.wikidata.org/entity/Q19997512>', 'Everett Fahy'), ('<http://www.wikidata.org/entity/Q457739>', 'Leo Steinberg'), ('<http://www.wikidata.org/entity/Q88907>', 'Ernst Kitzinger')]\n",
      "('Humboldt University of Berlin', '<http://www.wikidata.org/entity/Q152087>', 52.518, 13.393, 'institution') [('<http://www.wikidata.org/entity/Q90407>', 'Richard Krautheimer')]\n",
      "('Ludwig Maximilian University of Munich', '<http://www.wikidata.org/entity/Q55044>', 48.15, 11.58, 'institution') [('<http://www.wikidata.org/entity/Q88907>', 'Ernst Kitzinger')]\n",
      "('New York University', '<http://www.wikidata.org/entity/Q49210>', 40.73, -73.99, 'institution') [('<http://www.wikidata.org/entity/Q90407>', 'Richard Krautheimer'), ('<http://www.wikidata.org/entity/Q457739>', 'Leo Steinberg'), ('<http://www.wikidata.org/entity/Q1712683>', 'Julius S. Held')]\n",
      "('University of Halle-Wittenberg', '<http://www.wikidata.org/entity/Q32120>', 51.486, 11.968, 'institution') [('<http://www.wikidata.org/entity/Q90407>', 'Richard Krautheimer')]\n",
      "('University of Oxford New College', '<http://www.wikidata.org/entity/Q1376987>', 51.754, -1.251, 'institution') [('<http://www.wikidata.org/entity/Q3051533>', 'Ellis Waterhouse')]\n",
      "('New College', '<http://www.wikidata.org/entity/Q1376987>', 51.754, -1.251, 'institution') [('<http://www.wikidata.org/entity/Q3051533>', 'Ellis Waterhouse')]\n",
      "('Barnard College', '<http://www.wikidata.org/entity/Q167733>', 40.809, -73.96, 'institution') [('<http://www.wikidata.org/entity/Q1712683>', 'Julius S. Held')]\n",
      "('Magdalen College', '<http://www.wikidata.org/entity/Q81162>', 51.751, -1.246, 'institution') [('<http://www.wikidata.org/entity/Q3051533>', 'Ellis Waterhouse')]\n",
      "('Columbia University', '<http://www.wikidata.org/entity/Q49088>', 40.807, -73.96, 'institution') [('<http://www.wikidata.org/entity/Q1712683>', 'Julius S. Held')]\n",
      "('Harvard University Center for Italian Renaissance Studies', '<http://www.wikidata.org/entity/Q3558578>', 43.794, 11.315, 'institution') [('<http://www.wikidata.org/entity/Q61913691>', 'Luisa Vertova')]\n",
      "('Villa I Tatti', '<http://www.wikidata.org/entity/Q3558578>', 43.794, 11.315, 'institution') [('<http://www.wikidata.org/entity/Q61913691>', 'Luisa Vertova')]\n",
      "('University of Genoa', '<http://www.wikidata.org/entity/Q593321>', 44.415, 8.9257, 'institution') [('<http://www.wikidata.org/entity/Q1373290>', 'Eugenio Battisti')]\n",
      "('University of Manchester', '<http://www.wikidata.org/entity/Q230899>', 53.465, -2.233, 'institution') [('<http://www.wikidata.org/entity/Q3051533>', 'Ellis Waterhouse')]\n",
      "('University of Birmingham', '<http://www.wikidata.org/entity/Q223429>', 52.45, -1.93, 'institution') [('<http://www.wikidata.org/entity/Q3051533>', 'Ellis Waterhouse')]\n",
      "('Hunter College', '<http://www.wikidata.org/entity/Q1446181>', 40.768, -73.96, 'institution') [('<http://www.wikidata.org/entity/Q457739>', 'Leo Steinberg')]\n",
      "('University of Chicago', '<http://www.wikidata.org/entity/Q131252>', 41.789, -87.59, 'institution') [('<http://www.wikidata.org/entity/Q1715096>', 'Ulrich Middeldorf')]\n",
      "('Leipzig University', '<http://www.wikidata.org/entity/Q154804>', 51.338, 12.378, 'institution') [('<http://www.wikidata.org/entity/Q3057287>', 'Ernst Steinmann')]\n",
      "('University of Cambridge', '<http://www.wikidata.org/entity/Q35794>', 52.205, 0.1172, 'institution') [('<http://www.wikidata.org/entity/Q537874>', 'John Pope-Hennessy'), ('<http://www.wikidata.org/entity/Q88907>', 'Ernst Kitzinger')]\n",
      "('University of Oxford', '<http://www.wikidata.org/entity/Q34433>', 51.755, -1.255, 'institution') [('<http://www.wikidata.org/entity/Q537874>', 'John Pope-Hennessy')]\n",
      "('University of Pennsylvania', '<http://www.wikidata.org/entity/Q49117>', 39.953, -75.19, 'institution') [('<http://www.wikidata.org/entity/Q457739>', 'Leo Steinberg')]\n",
      "('University of Hamburg', '<http://www.wikidata.org/entity/Q156725>', 53.566, 9.9838, 'institution') [('<http://www.wikidata.org/entity/Q60185>', 'Aby Warburg')]\n",
      "('University of Kentucky', '<http://www.wikidata.org/entity/Q1360303>', 38.033, -84.5, 'institution') [('<http://www.wikidata.org/entity/Q90407>', 'Richard Krautheimer')]\n",
      "('Tor Vergata University of Rome', '<http://www.wikidata.org/entity/Q1031803>', 41.851, 12.629, 'institution') [('<http://www.wikidata.org/entity/Q1373290>', 'Eugenio Battisti')]\n"
     ]
    }
   ],
   "source": [
    "loc_list = ['country', 'city', 'village', 'capital', 'state', 'region', 'municipality', 'county', 'frazione', 'comune', 'city-state', 'enclave']\n",
    "firstdict = {}\n",
    "final = {}\n",
    "for hist, prop, place in g.triples((None, wdt.P69, None)):\n",
    "    for eduplace, hasname, eduplacename in g.triples((place, RDFS.label, None)):\n",
    "        #print(eduplacename)\n",
    "        for edup, hascoordinates, coord in g.triples((eduplace, wdt.P625, None)):\n",
    "            for edupl, istype, placetype in g.triples((edup, wdt.P31, None)):\n",
    "                for plctype, named, typelabel in g.triples((placetype, RDFS.label, None)):\n",
    "                    #print(plctype)\n",
    "                    for historian, p, name in g.triples(( hist, RDFS.label, None)):\n",
    "                        if \"wikidata.org/entity/\" in str(historian):\n",
    "                            type_label = typelabel\n",
    "                            check =  any(item in loc_list for item in type_label)\n",
    "                            if check:\n",
    "                                loc = \"geoloc\"\n",
    "                            else:\n",
    "                                loc = 'institution'\n",
    "                            key = (eduplacename.strip(), \"<\" + place.strip() +\">\", float(coord.split(\" \")[1][1:-2][0:6]), float(coord.split(\" \")[0][2:-2][0:6]), loc)\n",
    "                            value = tuple([\"<\" + hist.strip() +\">\", name.strip()])\n",
    "                            if key not in firstdict.keys():\n",
    "                                firstdict[key] = set([value])\n",
    "                            else:\n",
    "                                firstdict[key].update([value])\n",
    "\n",
    "\n",
    "                    \n",
    "for hist, prop, place in g.triples((None, wdt.P108, None)):\n",
    "    for place, hasname, workplacename in g.triples((place, RDFS.label, None)):\n",
    "        for place, hasCoordinates, coord in g.triples((place, wdt.P625, None)):\n",
    "            for edupl, istype, placetype in g.triples((place, wdt.P31, None)):\n",
    "                for plctype, named, typelabel in g.triples((placetype, RDFS.label, None)):\n",
    "                    for historian, p, name in g.triples(( hist, RDFS.label, None)):   \n",
    "                        if \"wikidata.org/entity/\" in str(historian):\n",
    "                            type_label = typelabel\n",
    "                            check =  any(item in loc_list for item in type_label)\n",
    "                            if check:\n",
    "                                loc = \"geoloc\"\n",
    "                            else:\n",
    "                                loc = 'institution'\n",
    "                            key = (workplacename.strip(), \"<\" + place.strip() +\">\", float(coord.split(\" \")[1][1:-2][0:6]), float(coord.split(\" \")[0][2:-2][0:6]), loc)\n",
    "                            value = tuple([\"<\" + hist.strip() +\">\", name.strip()])\n",
    "                            if key not in firstdict.keys():\n",
    "                                firstdict[key] = set([value])\n",
    "                            else:\n",
    "                                firstdict[key].update([value])\n",
    "\n",
    "\n",
    "for k, v in firstdict.items(): #creation of a dictionary that has as key a tuple with the info for a place and as values a list of tuples of art historians connected to that place.\n",
    "    for el in v:\n",
    "        if k not in final.keys():\n",
    "            final[k] = [el]\n",
    "        else:\n",
    "            final[k].append(el)\n",
    "            \n",
    "#for k, v in final.items():\n",
    "    #print(k,v)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "related = {} #dictionary to collect the main subjects of an art historian -p921- present in ARTchives data \n",
    "for s,p,o in g.triples(( None, wdt.P170, None)):   \n",
    "    if \"wikidata.org/entity/\" in str(o):           \n",
    "        for hist, prop, obj in g.triples((o, wdt.P921, None)):     \n",
    "            for subj, pr, name in g.triples(( hist, RDFS.label, None)):   \n",
    "                key = tuple(['<' + str(hist) + '>', name.strip()])\n",
    "                value = '<' + str(obj) + '>'\n",
    "                if key not in related.keys(): #the dict has as keys the historians and as values the relative list of main subjects.\n",
    "                    related[key] = [value]\n",
    "                else:\n",
    "                    related[key].append(value)\n",
    "    \n",
    "#for k, v in related.items():\n",
    "    #print(k, v)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import json\n",
    "\n",
    "related_dict= {}\n",
    "\n",
    "\n",
    "for k, v in related.items():  #for each art historian I extract those main subjects which are defined as places in wikidatata \n",
    "    relatedlist = ' '.join(v)\n",
    "    \n",
    "\n",
    "    query_results = \"\"\"\n",
    "        PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
    "        SELECT DISTINCT ?place ?place_label ?coord (group_concat(?type_label ; separator=\"; \") as ?label) \n",
    "        WHERE {\n",
    "            VALUES ?place {\"\"\"+relatedlist+\"\"\"} . \n",
    "            ?place rdfs:label ?place_label . \n",
    "            FILTER (langMatches(lang(?place_label), \"EN\")) . ?place wdt:P625 ?coord; wdt:P31 ?type . ?type rdfs:label ?type_label . FILTER (langMatches(lang(?type_label), \"EN\"))\n",
    "            } \n",
    "            group by ?place ?place_label ?coord ?label\n",
    "        \"\"\"\n",
    "\n",
    "    # set the endpoint \n",
    "    sparql_wd = SPARQLWrapper(wikidata_endpoint)\n",
    "    # set the query\n",
    "    sparql_wd.setQuery(query_results)\n",
    "    # set the returned format\n",
    "    sparql_wd.setReturnFormat(JSON)\n",
    "    # get the results\n",
    "    results = sparql_wd.query().convert()\n",
    "    \n",
    "    #with open('q1.json', 'w') as f:\n",
    "        #json.dump(results, f)\n",
    "\n",
    "    for result in results[\"results\"][\"bindings\"]:\n",
    "        #print(v, result)\n",
    "        place = '<' + str(result[\"place\"][\"value\"]) + '>'\n",
    "        place_name = result[\"place_label\"][\"value\"]\n",
    "        coord = result[\"coord\"][\"value\"][6:-1].split(\" \")\n",
    "        type_label = result[\"label\"][\"value\"].split(\"; \")[0]\n",
    "        type_label_list = type_label.split(\" \")\n",
    "        check =  any(item in loc_list for item in type_label_list)\n",
    "        if check:\n",
    "            loc = \"geoloc\"\n",
    "        else:\n",
    "            loc = 'institution'\n",
    "        key = tuple([place_name, place, float(coord[1][0:6]), float(coord[0][0:6]), loc])\n",
    "        for value in v:\n",
    "            if value == str(key[1]):\n",
    "                #print(k[1], place_name)\n",
    "                if key not in related_dict.keys():\n",
    "                    related_dict[key] = set([k])\n",
    "                else: \n",
    "                    related_dict[key].update([k])\n",
    "                \n",
    "\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "for k, v in final.items():\n",
    "    for el in v:\n",
    "        if k not in related_dict.keys():\n",
    "            related_dict[k] = set([el])\n",
    "        else:\n",
    "            related_dict[k].update([el])\n",
    "    \n",
    "    \n",
    "#for k, v in related_dict.items():\n",
    "    #print(k, v)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2608085969c4dbb820126de070d6b6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[41.080684, -30.683374], close_popup_on_click=False, controls=(ZoomControl(options=['position', 'zo…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#If runned in Binder, click on File > Trust Notebook to properly visualize maps\n",
    "#!pip install ipywidgets\n",
    "#!pip install ipyleaflet\n",
    "from ipywidgets import HTML\n",
    "\n",
    "from ipyleaflet import Map, Marker, Popup, LayersControl, AwesomeIcon\n",
    "\n",
    "center = (41.080684, -30.683374)\n",
    "\n",
    "\n",
    "m = Map(center=center, zoom=3, close_popup_on_click=False)\n",
    "\n",
    "\n",
    "\n",
    "for k,v in related_dict.items():\n",
    "    names = []\n",
    "    for value in v:\n",
    "        if value[0] not in names:\n",
    "            names.append(\"<a href='http://artchives.fondazionezeri.unibo.it/historian-\" + value[0][32:-1] + \"'>\" + value[1] + \"</a>\" + \". \")\n",
    "    namelist = \" \".join(names)\n",
    "    #print(namelist)\n",
    "    if 'geoloc' in k[4]:\n",
    "        icon2 = AwesomeIcon(\n",
    "        name = \"map-marker\",\n",
    "        marker_color='blue',\n",
    "        icon_color='white',\n",
    "        spin=False\n",
    "        )\n",
    "        marker = Marker(icon = icon2, location=(k[2], k[3]))\n",
    "        m.add_layer(marker)\n",
    "        #message = HTML()\n",
    "        #marker.popup = message\n",
    "        #message.description = \"\"\n",
    "    #message.value = \"<b>\" + k[0] + \"</b>\" + \"<br>\"  + namelist\n",
    "    else:\n",
    "        icon2 = AwesomeIcon(\n",
    "        name = \"bank\",\n",
    "        marker_color='green',\n",
    "        icon_color='white',\n",
    "        spin=False\n",
    "            )\n",
    "        marker = Marker(icon = icon2, location=(k[2], k[3]))\n",
    "        m.add_layer(marker)\n",
    "    message = HTML()\n",
    "    marker.popup = message\n",
    "    message.description = \"\"\n",
    "    message.value = \"<b>\" + k[0] + \"</b>\" + \"<br>\" + namelist\n",
    "    \n",
    "        \n",
    "\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The distribution of selected art historians’ places of education and activity: visualizing RQ2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_dict = {} #dict that has as keys art historians and as values the list of related places. \n",
    "hist_list = []\n",
    "for k, v in related_dict.items():\n",
    "    for value in v:\n",
    "        if value not in hist_list:\n",
    "            hist_list.append(value)\n",
    "    for el in hist_list:\n",
    "        if el in v:\n",
    "            if el not in hist_dict.keys():\n",
    "                hist_dict[el] = [k]\n",
    "            else:\n",
    "                hist_dict[el].append(k)\n",
    "        \n",
    "\n",
    "#for k, v in hist_dict.items():            \n",
    "    #print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2810f1a2d09a4e9a826a5a808e18b73f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[41.080684, -30.683374], close_popup_on_click=False, controls=(ZoomControl(options=['position', 'zo…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipyleaflet import LayerGroup\n",
    "import random \n",
    "center = (41.080684, -30.683374)\n",
    "\n",
    "colors = ['red', 'darkred', 'lightred', 'orange', 'beige', 'green', 'darkgreen', 'lightgreen', 'blue', 'darkblue', 'lightblue', 'purple', 'darkpurple', 'pink', 'cadetblue', 'gray', 'lightgray', 'black']\n",
    "\n",
    "\n",
    "m = Map(center=center, zoom=3, close_popup_on_click=False)\n",
    "control = LayersControl(position='topright')\n",
    "m.add_control(control)\n",
    "\n",
    "for k,v in hist_dict.items():\n",
    "    layer_group = LayerGroup(layers=(), name=k[1]) #creating different layers for different historians\n",
    "    m.add_layer(layer_group)\n",
    "    #print(k, v)\n",
    "    icon2 = AwesomeIcon(\n",
    "        name = \"map-marker\",\n",
    "        marker_color= random.choice(colors),\n",
    "        icon_color='white',\n",
    "        spin=False\n",
    "        )\n",
    "    for value in v:\n",
    "        marker = Marker(icon = icon2, location=(value[2], value[3]))\n",
    "        message = HTML()\n",
    "        marker.popup = message\n",
    "        message.description = \"\"\n",
    "        message.value =\"<b>\" + \"<a href='http://artchives.fondazionezeri.unibo.it/historian-\" + k[0][32:-1] +\"'>\" + k[1] + \"</a>\" + \"</b>\" + \"<br>\"  + value[0]\n",
    "        layer_group.add_layer(marker)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. The distribution of art historians’ relations with experts of their times: visualizing RQ3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "people = []\n",
    "for k, v in related.items():   \n",
    "    relatedlist = ' '.join(v)\n",
    "    #print(relatedlist)\n",
    "    query_res = \"\"\"\n",
    "        PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
    "        PREFIX wd: <http://www.wikidata.org/entity/>\n",
    "        SELECT DISTINCT ?person ?person_label ?occupation ?deathdate\n",
    "        WHERE {\n",
    "            VALUES ?person {\"\"\"+relatedlist+\"\"\"} . \n",
    "            ?person wdt:P31 wd:Q5; rdfs:label ?person_label . \n",
    "            VALUES ?occupation {wd:Q1792450 wd:Q201788 wd:Q36180 wd:Q4164507 wd:Q1126160 wd:Q10732476 wd:Q1622272 wd:Q22132694} .  \n",
    "            ?person wdt:P106 ?occupation ; wdt:P570 ?deathdate.\n",
    "            FILTER (langMatches(lang(?person_label), \"EN\") ) \n",
    "            } \n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "    # set the endpoint \n",
    "    sparql_wd = SPARQLWrapper(wikidata_endpoint)\n",
    "    # set the query\n",
    "    sparql_wd.setQuery(query_res)\n",
    "    # set the returned format\n",
    "    sparql_wd.setReturnFormat(JSON)\n",
    "    # get the results\n",
    "    results = sparql_wd.query().convert()\n",
    "\n",
    "    for result in results[\"results\"][\"bindings\"]:\n",
    "        #print(result)\n",
    "        person = '<' + str(result[\"person\"][\"value\"]) + '>'\n",
    "        person_name = str(result[\"person_label\"][\"value\"])\n",
    "        death_date = int(result[\"deathdate\"][\"value\"][0:4])\n",
    "        key = tuple([person_name, person])\n",
    "        if death_date > 1850:\n",
    "            for value in v:\n",
    "                if value == str(key[1]):\n",
    "                    tupla = tuple([k[1], k[0], person_name, person, 2])\n",
    "                    if tupla not in people:\n",
    "                        people.append(tupla)\n",
    "\n",
    "            \n",
    "#print(people)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "coll_related = {}\n",
    "for coll,p,hist in g.triples(( None, wdt.P170, None)):\n",
    "    for historian, proper, hist_name in g.triples((hist, RDFS.label, None)):     # people \"o\" are the creator \"wdt.P170\" of a collection \"s\"\n",
    "        for collection, pr, coll_name in g.triples(( coll, RDFS.label, None)):   \n",
    "            for col, prop, content in g.triples((coll, wdt.P921, None)):     \n",
    "                for cont, pro, content_label in g.triples(( content, RDFS.label, None)): \n",
    "                    if \"wikidata.org/entity/\" in str(content):    \n",
    "                        key = tuple([hist_name.strip(), '<' + str(hist) + '>'])\n",
    "                        value = '<' + str(content) + '>'\n",
    "                        if key not in coll_related.keys():\n",
    "                            coll_related[key] = set([value])\n",
    "                        else:\n",
    "                            coll_related[key].add(value)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "collection_related = {}\n",
    "for coll,p,hist in g.triples(( None, wdt.P170, None)):\n",
    "    for historian, proper, hist_name in g.triples((hist, RDFS.label, None)):     \n",
    "        for collection, pr, coll_name in g.triples(( coll, RDFS.label, None)):   \n",
    "            for col, prop, content in g.triples((coll, art.hasSubjectPeople, None)):     \n",
    "                for cont, pro, content_label in g.triples(( content, RDFS.label, None)): \n",
    "                    if \"wikidata.org/entity/\" in str(content):    \n",
    "                        key = tuple([hist_name.strip(), '<' + str(hist) + '>'])\n",
    "                        value = '<' + str(content) + '>'\n",
    "                        if key not in collection_related.keys():\n",
    "                            collection_related[key] = set([value])\n",
    "                        else:\n",
    "                            collection_related[key].add(value)\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in collection_related.items(): \n",
    "    collection_list = ' '.join(v)\n",
    "    query_res = \"\"\"\n",
    "        PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
    "        PREFIX wd: <http://www.wikidata.org/entity/>\n",
    "        PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\n",
    "        SELECT DISTINCT ?person ?person_label ?occupation ?deathdate\n",
    "        WHERE {\n",
    "            VALUES ?person {\"\"\"+collection_list+\"\"\"} . \n",
    "            ?person wdt:P31 wd:Q5; rdfs:label ?person_label \n",
    "            FILTER (langMatches(lang(?person_label), \"EN\")) . \n",
    "            }  \n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "    # set the endpoint \n",
    "    sparql_wd = SPARQLWrapper(wikidata_endpoint)\n",
    "    # set the query\n",
    "    sparql_wd.setQuery(query_res)\n",
    "    # set the returned format\n",
    "    sparql_wd.setReturnFormat(JSON)\n",
    "    # get the results\n",
    "    results = sparql_wd.query().convert()\n",
    "\n",
    "    for result in results[\"results\"][\"bindings\"]:\n",
    "        #print(result)\n",
    "        person = '<' + str(result[\"person\"][\"value\"]) + '>'\n",
    "        person_name = str(result[\"person_label\"][\"value\"])\n",
    "        key = tuple([person_name, person])\n",
    "        for value in v:\n",
    "            if value == str(key[1]):\n",
    "                tupla = tuple([k[0], k[1], person_name, person, 3])\n",
    "                if tupla not in people:\n",
    "                    #print(tupla)\n",
    "                    people.append(tupla)\n",
    "                    \n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Werner Cohn', '<http://www.wikidata.org/entity/Q18935222>', 'Thomas Mann', '<http://www.wikidata.org/entity/Q37030>', 3)\n",
      "('Werner Cohn', '<http://www.wikidata.org/entity/Q18935222>', 'Friedrich Nietzsche', '<http://www.wikidata.org/entity/Q9358>', 3)\n",
      "('Werner Cohn', '<http://www.wikidata.org/entity/Q18935222>', 'Carlo Carrà', '<http://www.wikidata.org/entity/Q168496>', 3)\n"
     ]
    }
   ],
   "source": [
    "for k, v in coll_related.items(): \n",
    "    coll_list = ' '.join(v)\n",
    "    query_res = \"\"\"\n",
    "        PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
    "        PREFIX wd: <http://www.wikidata.org/entity/>\n",
    "        PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\n",
    "        SELECT DISTINCT ?person ?person_label ?occupation ?deathdate\n",
    "        WHERE {\n",
    "            VALUES ?person {\"\"\"+coll_list+\"\"\"} . \n",
    "            ?person wdt:P31 wd:Q5; rdfs:label ?person_label \n",
    "            optional {?person wdt:P570 ?deathdate. FILTER (?deathdate > \"1850-01-01\"^^xsd:dateTime)} .\n",
    "            VALUES ?occupation {wd:Q1792450 wd:Q201788 wd:Q36180 wd:Q4164507 wd:Q1126160 wd:Q10732476 wd:Q1622272 wd:Q22132694}. \n",
    "            ?person wdt:P106 ?occupation .\n",
    "            FILTER (langMatches(lang(?person_label), \"EN\")) . \n",
    "            }  \n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "    # set the endpoint \n",
    "    sparql_wd = SPARQLWrapper(wikidata_endpoint)\n",
    "    # set the query\n",
    "    sparql_wd.setQuery(query_res)\n",
    "    # set the returned format\n",
    "    sparql_wd.setReturnFormat(JSON)\n",
    "    # get the results\n",
    "    results = sparql_wd.query().convert()\n",
    "\n",
    "    for result in results[\"results\"][\"bindings\"]:\n",
    "        #print(result)\n",
    "        person = '<' + str(result[\"person\"][\"value\"]) + '>'\n",
    "        person_name = str(result[\"person_label\"][\"value\"])\n",
    "        key = tuple([person_name, person])\n",
    "        if \"deathdate\" in result: \n",
    "            death_date = int(result[\"deathdate\"][\"value\"][0:4])\n",
    "            if death_date > 1850 or \"deathdate\" not in result:\n",
    "                for value in v:\n",
    "                    if value == str(key[1]):\n",
    "                        tupla = tuple([k[0], k[1], person_name, person, 3])\n",
    "                        if tupla not in people and k[0] != person_name:\n",
    "                            #print(tupla)\n",
    "                            people.append(tupla)\n",
    "\n",
    "#print(people)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdpeople_query = \"\"\" \n",
    "PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
    "PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\n",
    "SELECT DISTINCT ?historian ?student ?student_label ?master ?master_label ?influencer ?influencer_label ?signper ?signper_label ?birthdate ?deathdate \n",
    "WHERE {\n",
    "        VALUES ?historian {\"\"\"+historians+\"\"\"} . \n",
    "        optional {?historian wdt:P802 ?student . \n",
    "        ?student rdfs:label ?student_label .\n",
    "        FILTER (langMatches(lang(?student_label), \"EN\")). \n",
    "        }\n",
    "        optional {?historian wdt:P1066 ?master . \n",
    "        ?master rdfs:label ?master_label .\n",
    "        FILTER (langMatches(lang(?master_label), \"EN\")). \n",
    "        }\n",
    "        optional {?historian wdt:P737 ?influencer . \n",
    "        ?influencer rdfs:label ?influencer_label .\n",
    "        FILTER (langMatches(lang(?influencer_label), \"EN\")).\n",
    "        } \n",
    "        optional {?historian wdt:P3342 ?signper . \n",
    "        ?signper rdfs:label ?signper_label .\n",
    "        FILTER (langMatches(lang(?signper_label), \"EN\")) . \n",
    "        }\n",
    "    } \n",
    "\"\"\"\n",
    "\n",
    "sparql_wd = SPARQLWrapper(wikidata_endpoint)\n",
    "    # set the query\n",
    "sparql_wd.setQuery(wdpeople_query)\n",
    "    # set the returned format\n",
    "sparql_wd.setReturnFormat(JSON)\n",
    "    # get the results\n",
    "results = sparql_wd.query().convert()\n",
    "\n",
    "for result in results[\"results\"][\"bindings\"]:\n",
    "    #print(result)\n",
    "    historian = result[\"historian\"][\"value\"]\n",
    "    if \"influencer\" in result: \n",
    "        influencer = result[\"influencer\"][\"value\"]\n",
    "        #print(influencer)\n",
    "        if \"influencer_label\" in result: \n",
    "            influencer_label = result[\"influencer_label\"][\"value\"]\n",
    "            #print(\"influencer:\", influencer, influencer_label)\n",
    "\n",
    "                    # only if both uri and label are found we add them to \n",
    "            g.add(( URIRef(historian) , URIRef(wdt.P737) , URIRef(influencer) ))\n",
    "            g.add(( URIRef(influencer) , RDFS.label , Literal(influencer_label) ))\n",
    "            \n",
    "           \n",
    "    if \"student\" in result: \n",
    "        student = result[\"student\"][\"value\"]\n",
    "        #print(historian)\n",
    "        if \"student_label\" in result: \n",
    "            student_label = result[\"student_label\"][\"value\"]\n",
    "            #print(\"historian:\", historian, \"student:\", student, student_label)\n",
    "\n",
    "                        # only if both uri and label are found we add them to \n",
    "            g.add(( URIRef(historian) , URIRef(wdt.P802) , URIRef(student) ))\n",
    "            g.add(( URIRef(student) , RDFS.label , Literal(student_label) )) \n",
    "           \n",
    "    \n",
    "    if \"master\" in result: \n",
    "        master = result[\"master\"][\"value\"]\n",
    "        if \"master_label\" in result: \n",
    "            master_label = result[\"master_label\"][\"value\"]\n",
    "            #print(\"historian:\", historian, \"master:\", master_label)\n",
    "\n",
    "                        # only if both uri and label are found we add them to \n",
    "            g.add(( URIRef(historian) , URIRef(wdt.P1066) , URIRef(master) ))\n",
    "            g.add(( URIRef(master) , RDFS.label , Literal(master_label) ))\n",
    "            \n",
    "                \n",
    "    \n",
    "    if \"signper\" in result: \n",
    "        signper = result[\"signper\"][\"value\"]\n",
    "        if \"signper_label\" in result: \n",
    "            signper_label = result[\"signper_label\"][\"value\"]\n",
    "            #print(\"signper:\", signper, signper_label)\n",
    "\n",
    "                        # only if both uri and label are found we add them to \n",
    "            g.add(( URIRef(historian) , URIRef(wdt.P3342) , URIRef(signper) ))\n",
    "            g.add(( URIRef(signper) , RDFS.label , Literal(signper_label) ))\n",
    "           \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.serialize(destination='artchives3.nq', format='nquads') #Desktop/dhdk_epds/resources/\n",
    "result = g.parse(\"artchives3.nq\", format='nquads')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for hist, prop, influencer in g.triples((None, wdt.P737, None)):\n",
    "    #print(hist)\n",
    "    for influencer, hasname, influencername in g.triples((influencer, RDFS.label, None)):\n",
    "        for historian, p, name in g.triples(( hist, RDFS.label, None)):\n",
    "            if \"wikidata.org/entity/\" in str(hist):\n",
    "                tuplawd = tuple([name.strip(), \"<\" + hist.strip() +\">\", influencername.strip(), \"<\" + influencer.strip() +\">\", 1])\n",
    "                if tuplawd not in people:\n",
    "                    people.append(tuplawd)\n",
    "                \n",
    "for hist, prop, student in g.triples((None, wdt.P802, None)):\n",
    "    #print(hist)\n",
    "    for historian, p, name in g.triples(( hist, RDFS.label, None)):\n",
    "        for student, hasname, studentname in g.triples((student, RDFS.label, None)):\n",
    "            if \"wikidata.org/entity/\" in str(hist):  \n",
    "                tuplawd = tuple([name.strip(), \"<\" + hist.strip() +\">\", studentname.strip(), \"<\" + student.strip() +\">\", 1])\n",
    "                if tuplawd not in people:\n",
    "                    people.append(tuplawd)\n",
    "\n",
    "for hist, prop, master in g.triples((None, wdt.P1066, None)):\n",
    "    #print(hist)\n",
    "    for historian, p, name in g.triples(( hist, RDFS.label, None)):\n",
    "        for master, hasname, mastername in g.triples((master, RDFS.label, None)):\n",
    "            if \"wikidata.org/entity/\" in str(hist):  \n",
    "                tuplawd = tuple([name.strip(), \"<\" + hist.strip() +\">\", mastername.strip(), \"<\" + master.strip() +\">\", 1])\n",
    "                if tuplawd not in people:\n",
    "                    people.append(tuplawd)\n",
    "                \n",
    "                \n",
    "for hist, prop, signper in g.triples((None, wdt.P3342, None)):\n",
    "    #print(hist)\n",
    "    for historian, p, name in g.triples(( hist, RDFS.label, None)):\n",
    "        for signper, hasname, signpername in g.triples((signper, RDFS.label, None)):\n",
    "            if \"wikidata.org/entity/\" in str(hist):  \n",
    "                tuplawd = tuple([name.strip(), \"<\" + hist.strip() +\">\", signpername.strip(), \"<\" + signper.strip() +\">\", 1])\n",
    "                if tuplawd not in people:\n",
    "                    people.append(tuplawd)\n",
    "                \n",
    "#print(people)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('people.csv', mode='w') as my_file:\n",
    "    my_writer = csv.writer(my_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_ALL)\n",
    "    # write the column names\n",
    "    my_writer.writerow(['art_hist', 'art_hist_uri','person', 'person_uri', 'weight'])\n",
    "    \n",
    "    # access the list of tuples of the query results\n",
    "    for res in people:\n",
    "        # write in the csv\n",
    "        my_writer.writerow([res[0], res[1], res[2], res[3], res[4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>art_hist</th>\n",
       "      <th>art_hist_uri</th>\n",
       "      <th>person</th>\n",
       "      <th>person_uri</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Federico Zeri</td>\n",
       "      <td>&lt;http://www.wikidata.org/entity/Q1089074&gt;</td>\n",
       "      <td>Daniel Wildenstein</td>\n",
       "      <td>&lt;http://www.wikidata.org/entity/Q723358&gt;</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Federico Zeri</td>\n",
       "      <td>&lt;http://www.wikidata.org/entity/Q1089074&gt;</td>\n",
       "      <td>Denis Mahon</td>\n",
       "      <td>&lt;http://www.wikidata.org/entity/Q3705445&gt;</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Federico Zeri</td>\n",
       "      <td>&lt;http://www.wikidata.org/entity/Q1089074&gt;</td>\n",
       "      <td>Giuliano Briganti</td>\n",
       "      <td>&lt;http://www.wikidata.org/entity/Q3769356&gt;</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Federico Zeri</td>\n",
       "      <td>&lt;http://www.wikidata.org/entity/Q1089074&gt;</td>\n",
       "      <td>Frederick Antal</td>\n",
       "      <td>&lt;http://www.wikidata.org/entity/Q215037&gt;</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Federico Zeri</td>\n",
       "      <td>&lt;http://www.wikidata.org/entity/Q1089074&gt;</td>\n",
       "      <td>Mario Praz</td>\n",
       "      <td>&lt;http://www.wikidata.org/entity/Q981971&gt;</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        art_hist                               art_hist_uri  \\\n",
       "0  Federico Zeri  <http://www.wikidata.org/entity/Q1089074>   \n",
       "1  Federico Zeri  <http://www.wikidata.org/entity/Q1089074>   \n",
       "2  Federico Zeri  <http://www.wikidata.org/entity/Q1089074>   \n",
       "3  Federico Zeri  <http://www.wikidata.org/entity/Q1089074>   \n",
       "4  Federico Zeri  <http://www.wikidata.org/entity/Q1089074>   \n",
       "\n",
       "               person                                 person_uri  weight  \n",
       "0  Daniel Wildenstein   <http://www.wikidata.org/entity/Q723358>       2  \n",
       "1         Denis Mahon  <http://www.wikidata.org/entity/Q3705445>       2  \n",
       "2   Giuliano Briganti  <http://www.wikidata.org/entity/Q3769356>       2  \n",
       "3     Frederick Antal   <http://www.wikidata.org/entity/Q215037>       2  \n",
       "4          Mario Praz   <http://www.wikidata.org/entity/Q981971>       2  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#! pip install pandas\n",
    "import pandas as pd\n",
    "# parse the csv into a dataframe\n",
    "df = pd.read_csv(\"people.csv\")\n",
    "# print the first 5 rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"750px\"\n",
       "            src=\"people.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x11ff065e0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!pip install pyvis\n",
    "\n",
    "from pyvis import network as net\n",
    "\n",
    "\n",
    "\n",
    "people_net = net.Network(height=\"750px\", width=\"100%\", bgcolor=\"white\", font_color=\"#23f5ad\", notebook=\"True\", heading=\"The distribution of art historians' relations with experts of their times\")\n",
    "\n",
    "# set the physics layout of the network\n",
    "people_net.barnes_hut()\n",
    "people_data = pd.read_csv(\"people.csv\")\n",
    "\n",
    "sources = people_data['art_hist']\n",
    "targets = people_data['person']\n",
    "weights = people_data['weight']\n",
    "uri = people_data['art_hist_uri']\n",
    "\n",
    "edge_data = zip(sources, targets, weights)\n",
    "\n",
    "for e in edge_data:\n",
    "    #print(e)\n",
    "    src = e[0]\n",
    "    dst = e[1]\n",
    "    w = e[2]\n",
    "\n",
    "\n",
    "    people_net.add_node(src, src, title=src, color= \"#1cae81\", shape='dot')\n",
    "    people_net.add_node(dst, dst,  title=dst, color= \"#1cae81\", shape='dot')\n",
    "    if w == 1:\n",
    "        people_net.add_edge(src, dst, value=w, color=\"orange\")\n",
    "    elif w == 2:\n",
    "        people_net.add_edge(src, dst, value=w, color=\"grey\")\n",
    "    elif w == 3:\n",
    "        people_net.add_edge(src, dst, value=w, color=\"#1cae81\")\n",
    "\n",
    "neighbor_map = people_net.get_adj_list()\n",
    "\n",
    "# add neighbor data to node hover data\n",
    "for node in people_net.nodes:\n",
    "    #print(node)\n",
    "    node[\"title\"] = \"<b>\" + node[\"title\"] + \"</b>\"+ \" relations:<br>\" + \"<br>\".join(neighbor_map[node[\"id\"]])\n",
    "    node[\"size\"] = 70 + (len(neighbor_map[node[\"id\"]])*10)  #len(neighbor_map[node[\"id\"]]) #70 + (len(neighbor_map[node[\"id\"]])*10) \n",
    "    node[\"label\"] = node[\"id\"] \n",
    "    node[\"borderWidthSelected\"] = 5 \n",
    "    if node[\"label\"] in arthistorians_names:\n",
    "        node[\"color\"] = \"#23f5ad\"\n",
    "        uripos = arthistorians_names.index(node[\"label\"])+1\n",
    "        uri = arthistorians_names[uripos]\n",
    "        #print(node[\"label\"], uri)\n",
    "        #node[\"title\"] = \"<br>\" + \"<b>\" + \"<a href='http://artchives.fondazionezeri.unibo.it/historian-\" + uri[32:-1] + \"'>\" + node[\"label\"] + \"</a>\" +  \"</b>\" +  \"<i>\" + \"  relations:<br>\" + \"</i>\"+ \"<hr>\" + \"<br>\".join(neighbor_map[node[\"id\"]]) \n",
    "        node[\"title\"] = \"<br>\" + \"<b>\" + node[\"label\"] + \"</b>\" +  \"<i>\" + \"  relations:<br>\" + \"</i>\"+ \"<hr>\"+ \"<br>\".join(neighbor_map[node[\"id\"]]) + \"<br>\" \n",
    "    else: \n",
    "        node[\"title\"] = \"<br>\" + \"<b>\" + node[\"label\"] + \"</b>\" +  \"<i>\" + \"  relations:<br>\" + \"</i>\"+ \"<hr>\"+ \"<br>\".join(neighbor_map[node[\"id\"]]) + \"<br>\" \n",
    "        \n",
    "print(len(people_net.edges))\n",
    "\n",
    "people_net.show(\"people.html\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. The distribution of art historians’ relations with their subjects of study: visualizing RQ4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query_periods = g.query(\n",
    "    \"\"\"PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
    "    SELECT ?hist_label ?hist ?period (SAMPLE(?label) AS ?period_label) \n",
    "    WHERE {?coll <https://w3id.org/artchives/hasSubjectPeriod> ?period ; rdfs:label ?coll_label \n",
    "    . ?coll wdt:P170 ?hist . ?hist rdfs:label ?hist_label .\n",
    "    ?period rdfs:label ?label . \n",
    "    }\n",
    "    GROUP BY ?period ?label ?hist ?hist_label \n",
    "    ORDER BY ?period\"\"\")\n",
    "\n",
    "periods = set()\n",
    "period_dict = {}\n",
    "for result in query_periods:\n",
    "    #print(result)\n",
    "    hist = tuple([result[0].strip(), '<' + str(result[1])+ '>'])\n",
    "    period = result[2].strip()\n",
    "    #print(period)\n",
    "    if hist not in period_dict.keys():\n",
    "        period_dict[hist] = set([period])\n",
    "    else:\n",
    "        period_dict[hist].add(period)\n",
    "    \n",
    "\n",
    "for k,v in period_dict.items():\n",
    "    #print(k, v)\n",
    "    for value in v:\n",
    "        periods.add('<' + str(value) + '>') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "period_list = ' '.join(periods)\n",
    "period_res = \"\"\"\n",
    "        PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
    "        PREFIX wd: <http://www.wikidata.org/entity/>\n",
    "        SELECT DISTINCT ?period ?period_label ?startdate ?enddate\n",
    "        WHERE {\n",
    "            VALUES ?period {\"\"\"+period_list+\"\"\"} . \n",
    "            ?period wdt:P580 ?startdate ; wdt:P582 ?enddate; rdfs:label ?period_label .\n",
    "            FILTER (langMatches(lang(?period_label), \"EN\"))\n",
    "            \n",
    "            } \n",
    "        \"\"\"\n",
    "sparql_wd = SPARQLWrapper(wikidata_endpoint)\n",
    "    # set the query\n",
    "sparql_wd.setQuery(period_res)\n",
    "    # set the returned format\n",
    "sparql_wd.setReturnFormat(JSON)\n",
    "    # get the results\n",
    "results = sparql_wd.query().convert()\n",
    "\n",
    "dates_dict = {}\n",
    "for result in results[\"results\"][\"bindings\"]:\n",
    "    period = '<' + str(result[\"period\"][\"value\"]) + '>'\n",
    "    period_label = result[\"period_label\"][\"value\"]\n",
    "    start = int(result[\"startdate\"][\"value\"][0:4])\n",
    "    end = int(result[\"enddate\"][\"value\"][0:4])\n",
    "    key = tuple([period, period_label.lower()])\n",
    "    years = tuple([start, end])\n",
    "    if key not in dates_dict.keys():\n",
    "        dates_dict[key] = years\n",
    "\n",
    "#for k, v in dates_dict.items():\n",
    "    #print(k,v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "related_artists = {}\n",
    "for coll,p,hist in g.triples(( None, wdt.P170, None)):\n",
    "    for historian, proper, hist_name in g.triples((hist, RDFS.label, None)):     \n",
    "        for collection, pr, coll_name in g.triples(( coll, RDFS.label, None)):   \n",
    "            for col, prop, content in g.triples((coll, art.hasSubjectArtist, None)):     \n",
    "                for cont, pro, content_label in g.triples(( content, RDFS.label, None)): \n",
    "                    if \"wikidata.org/entity/\" in str(content):    \n",
    "                        key = tuple([hist_name.strip(), '<' + str(hist) + '>'])\n",
    "                        value = '<' + str(content) + '>'\n",
    "                        if key not in related_artists.keys():\n",
    "                            related_artists[key] = set([value])\n",
    "                        else:\n",
    "                            related_artists[key].add(value)\n",
    "                            \n",
    "#for k, v in related_artists.items():\n",
    "    #print(k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "artist_dict = {}\n",
    "for k, v in related_artists.items(): \n",
    "    art_list = ' '.join(v)\n",
    "    query_art = \"\"\"\n",
    "        PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
    "        PREFIX wd: <http://www.wikidata.org/entity/>\n",
    "        SELECT DISTINCT ?person ?person_label ?occupation ?birthdate ?deathdate\n",
    "        WHERE {\n",
    "            VALUES ?person {\"\"\"+art_list+\"\"\"} . \n",
    "            ?person wdt:P31 wd:Q5; rdfs:label ?person_label .\n",
    "            ?person wdt:P569 ?birthdate ; wdt:P570 ?deathdate.\n",
    "            FILTER (langMatches(lang(?person_label), \"EN\")) . \n",
    "            } \n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "    # set the endpoint \n",
    "    sparql_wd = SPARQLWrapper(wikidata_endpoint)\n",
    "    # set the query\n",
    "    sparql_wd.setQuery(query_art)\n",
    "    # set the returned format\n",
    "    sparql_wd.setReturnFormat(JSON)\n",
    "    # get the results\n",
    "    results = sparql_wd.query().convert()\n",
    "\n",
    "    for result in results[\"results\"][\"bindings\"]:\n",
    "        #print(result)\n",
    "        artist = '<' + str(result[\"person\"][\"value\"]) + '>'\n",
    "        artist_name = str(result[\"person_label\"][\"value\"]) \n",
    "        death = str(result[\"deathdate\"][\"value\"]) \n",
    "        birth = str(result[\"birthdate\"][\"value\"])\n",
    "        key = tuple([artist, artist_name, int(birth[0:4]), int(death[0:4])])\n",
    "        for value in v:\n",
    "            if value == artist:\n",
    "                if key not in artist_dict.keys():      \n",
    "                    artist_dict[key] = set([k[0]])\n",
    "                else:\n",
    "                    artist_dict[key].add(k[0])\n",
    "\n",
    "#for k,v in artist_dict.items():\n",
    "    #print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "check_dict = {}\n",
    "for k, v in coll_related.items(): \n",
    "    coll_list = ' '.join(v)\n",
    "    query_res = \"\"\"\n",
    "        PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
    "        PREFIX wd: <http://www.wikidata.org/entity/>\n",
    "        SELECT DISTINCT ?person ?person_label ?occupation ?birthdate ?deathdate\n",
    "        WHERE {\n",
    "            VALUES ?person {\"\"\"+coll_list+\"\"\"} . \n",
    "            ?person wdt:P31 wd:Q5; rdfs:label ?person_label .\n",
    "            VALUES ?occupation {wd:Q1281618 wd:Q42973 wd:Q483501 wd:Q1028181 wd:Q329439} . \n",
    "            ?person wdt:P106 ?occupation ; wdt:P569 ?birthdate ; wdt:P570 ?deathdate.\n",
    "            FILTER (langMatches(lang(?person_label), \"EN\")) . \n",
    "            } \n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "    # set the endpoint \n",
    "    sparql_wd = SPARQLWrapper(wikidata_endpoint)\n",
    "    # set the query\n",
    "    sparql_wd.setQuery(query_res)\n",
    "    # set the returned format\n",
    "    sparql_wd.setReturnFormat(JSON)\n",
    "    # get the results\n",
    "    results = sparql_wd.query().convert()\n",
    "\n",
    "    for result in results[\"results\"][\"bindings\"]:\n",
    "        #print(result)\n",
    "        artist = '<' + str(result[\"person\"][\"value\"]) + '>'\n",
    "        artist_name = str(result[\"person_label\"][\"value\"]) \n",
    "        death = str(result[\"deathdate\"][\"value\"]) \n",
    "        birth = str(result[\"birthdate\"][\"value\"])\n",
    "        key = tuple([artist, artist_name, int(birth[0:4]), int(death[0:4])])\n",
    "        \n",
    "        for value in v:\n",
    "            #print(value)\n",
    "            if value == artist:\n",
    "                if key not in check_dict.keys():      \n",
    "                    check_dict[key] = set([k[0]])\n",
    "                else:\n",
    "                    check_dict[key].add(k[0])\n",
    "               \n",
    "                \n",
    "#for k, v in check_dict.items():\n",
    "    #if k not in artist_dict.items():\n",
    "        #print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "artist_rel = list()\n",
    "for k, v in artist_dict.items():\n",
    "    for value in v:\n",
    "        tupla = tuple([k[1], value, 1])\n",
    "        if tupla not in artist_rel:\n",
    "            artist_rel.append(tupla)\n",
    "        for el in v:\n",
    "            if value != el:\n",
    "                tupla = tuple([el, value, 1])\n",
    "                tuplabis = tuple([value, el, 1])\n",
    "                if tuplabis not in artist_rel:\n",
    "                    artist_rel.append(tupla)\n",
    "    \n",
    "#print(len(artist_rel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "count_dict = Counter(artist_rel)\n",
    "artist_rel_final = []\n",
    "\n",
    "for k, v in count_dict.items():\n",
    "    if v != 1:\n",
    "        x = list(k)\n",
    "        x[2] = v\n",
    "        k = tuple(x)\n",
    "    artist_rel_final.append(k)\n",
    "    \n",
    "#print(artist_rel_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for k, v in coll_related.items():\n",
    "    #print(k, v)\n",
    "    for key, value in dates_dict.items():\n",
    "        #print(key, value)\n",
    "        for artist, hist in artist_dict.items():\n",
    "            #print(artist, hist)\n",
    "            if key[0] in v and artist[0] in v:\n",
    "                if (value[0] <= artist[2] and value[1] >= artist[3]) or (value[0] >= artist[2] and value[1] <= artist[3]) or (value[0] >= artist[2] and (value[1] + 15) >= artist[3] and artist[2] >= value[1]) or (value[0] <= artist[2] and (value[1] - 15) >= artist[2] and value[1] <= artist[3]):\n",
    "                    tupla = tuple([k[0], artist[1], 2])\n",
    "                    #print(tupla)\n",
    "                    tupla_remove1 = tuple([k[0], artist[1], 1])\n",
    "                    tupla_remove2 = tuple([artist[1], k[0], 1])\n",
    "                    if tupla_remove1 in artist_rel_final: \n",
    "                        artist_rel_final.remove(tupla_remove1)\n",
    "                    elif tupla_remove2 in artist_rel_final: \n",
    "                        artist_rel_final.remove(tupla_remove2)\n",
    "                    artist_rel_final.append(tupla)\n",
    "                        \n",
    "#print(artist_rel_final)                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('artists.csv', mode='w') as my_file:\n",
    "    my_writer = csv.writer(my_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_ALL)\n",
    "    # write the column names\n",
    "    my_writer.writerow(['subj1','subj2','weight'])\n",
    "    \n",
    "    # access the list of tuples of the query results\n",
    "    for res in artist_rel_final:\n",
    "        # write in the csv\n",
    "        my_writer.writerow([res[0], res[1], res[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subj1</th>\n",
       "      <th>subj2</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Luigi Salerno</td>\n",
       "      <td>Federico Zeri</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Caravaggio</td>\n",
       "      <td>Luigi Salerno</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Donatello</td>\n",
       "      <td>John Pope-Hennessy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Federico Zeri</td>\n",
       "      <td>John Pope-Hennessy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wolfgang Lotz</td>\n",
       "      <td>Richard Krautheimer</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           subj1                subj2  weight\n",
       "0  Luigi Salerno        Federico Zeri       1\n",
       "1     Caravaggio        Luigi Salerno       1\n",
       "2      Donatello   John Pope-Hennessy       1\n",
       "3  Federico Zeri   John Pope-Hennessy       1\n",
       "4  Wolfgang Lotz  Richard Krautheimer       1"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parse the csv into a dataframe\n",
    "df = pd.read_csv(\"artists.csv\")\n",
    "# print the first 5 rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"750px\"\n",
       "            src=\"people.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x12077a9a0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "people_net = net.Network(height=\"750px\", width=\"100%\", bgcolor=\"white\", font_color=\"#1cae81\", notebook=\"True\", heading=\"The distribution of art historians' relations with their subjects of study\")\n",
    "\n",
    "# set the physics layout of the network\n",
    "people_net.barnes_hut()\n",
    "people_data = pd.read_csv(\"artists.csv\")\n",
    "\n",
    "sources = people_data['subj1']\n",
    "targets = people_data['subj2']\n",
    "weights = people_data['weight']\n",
    "\n",
    "\n",
    "edge_data = zip(sources, targets, weights)\n",
    "\n",
    "for e in edge_data:\n",
    "    #print(e)\n",
    "    src = e[0]\n",
    "    dst = e[1]\n",
    "    w = e[2]\n",
    "\n",
    "\n",
    "    people_net.add_node(src, src, title=src, color= \"#1cae81\")\n",
    "    people_net.add_node(dst, dst, title=dst, color= \"#1cae81\")\n",
    "    if w == 1:\n",
    "        people_net.add_edge(src, dst, value=w, color=\"grey\")\n",
    "    elif w == 2:\n",
    "        people_net.add_edge(src, dst, value=w, color=\"#1cae81\")\n",
    "    elif w == 3:\n",
    "        people_net.add_edge(src, dst, value=w, color=\"black\")\n",
    "    \n",
    "        \n",
    "\n",
    "neighbor_map = people_net.get_adj_list()\n",
    "\n",
    "# add neighbor data to node hover data\n",
    "for node in people_net.nodes:\n",
    "    #print(node)\n",
    "    \n",
    "    node[\"size\"] = 80 + (len(neighbor_map[node[\"id\"]])*10)   \n",
    "    node[\"borderWidthSelected\"] = 5\n",
    "    node[\"label\"] = node[\"id\"] \n",
    "    historians = set()\n",
    "    artists = set()\n",
    "    for el in (neighbor_map[node[\"id\"]]):\n",
    "        if el in arthistorians_names:\n",
    "            historians.add(el)\n",
    "        else: \n",
    "            artists.add(el)\n",
    "    if node[\"label\"] in arthistorians_names:\n",
    "        node[\"color\"] = \"#23f5ad\"\n",
    "        uripos = arthistorians_names.index(node[\"label\"])+1\n",
    "        uri = arthistorians_names[uripos]\n",
    "        #print(node[\"label\"], uri)\n",
    "        if len(historians) > 0:\n",
    "            node[\"title\"] = \"<br>\" + \"<b>\" + node[\"label\"] +  \"</b>\" +  \"<i>\" + \"  relations:<br>\" + \"</i>\"+ \"<hr>\" + \"<b>\" + \"Subjects of study\" + \"</b>\" + \"<br>\" + \"<br>\".join(artists) + \"<br>\" + \"<hr>\"+ \"<b>\" + \"Art historians\" + \"</b>\" + \"<br>\" + \"<br>\".join(historians)  \n",
    "        else:\n",
    "            node[\"title\"] = \"<br>\" + \"<b>\" + node[\"label\"] +   \"</b>\" +  \"<i>\" + \"  relations:<br>\" + \"</i>\"+ \"<hr>\" + \"<b>\" + \"Subjects of study\" + \"</b>\" + \"<br>\" + \"<br>\".join(artists)\n",
    "    \n",
    "        #+ \"<a href='http://artchives.fondazionezeri.unibo.it/historian-\" + uri[32:-1] + \"'>\" + node[\"label\"] + \"</a>\" +\n",
    "    else: \n",
    "        node[\"title\"] = \"<br>\" + \"<b>\" + node[\"label\"] + \"</b>\" +  \"<i>\" + \"  relations:<br>\" + \"</i>\"+ \"<hr>\" + \"<b>\" + \"Art historians\" + \"</b>\" + \"<br>\" + \"<br>\".join(historians) + \"<br>\" \n",
    "   \n",
    "        #print(historians)\n",
    "        #print(artists)\n",
    "people_net.show(\"people.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
